import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import io
from io import StringIO
from sklearn.preprocessing import MinMaxScaler
from sklearn.cluster import KMeans

import arff
from arff import dump as arff_dump

from sklearn.metrics import silhouette_score, silhouette_samples
from sklearn.metrics import davies_bouldin_score
from sklearn.metrics import calinski_harabasz_score
from sklearn.decomposition import PCA

from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import A4

# ====================================================
# CONFIGURAÃ‡ÃƒO INICIAL
# ====================================================
st.set_page_config(page_title="Projeto de AnÃ¡lise", layout="wide")
st.title("ðŸ“Š Projeto de AnÃ¡lise de Dados com Streamlit")

# ====================================================
# MENU LATERAL
# ====================================================
menu = st.sidebar.radio(
    "Selecione uma opÃ§Ã£o:",
    [
        "Gerar Histogramas", 
        "ClusterizaÃ§Ã£o (K-Means)",
        "AvaliaÃ§Ã£o dos Clusters",
        "Resumo Comparativo",
        "Resumo Comparativo e ExportaÃ§Ã£o em PDF"
    ]
)

# ====================================================
# FUNÃ‡ÃƒO PARA CARREGAR DADOS
# ====================================================
@st.cache_data
def load_data():
    path = "https://docs.google.com/spreadsheets/d/1supejFq9cpVVY_doGhtny902ti7H7rcTaaMvsFFGI3M/export?format=csv"
    return pd.read_csv(path, low_memory=False)

df = load_data()

# ==============================
# VARIÃVEIS PERSISTENTES
# ==============================
if "df_scaled" not in st.session_state:
    st.session_state.df_scaled = None

if "numeric_continuous" not in st.session_state:
    st.session_state.numeric_continuous = None

if "kmeans_model" not in st.session_state:
    st.session_state.kmeans_model = None

if "X" not in st.session_state:
    st.session_state.X = None

if "k_final" not in st.session_state:
    st.session_state.k_final = None

if "cols_nominal" not in st.session_state:
    st.session_state.cols_nominal = None

if "numeric_cols" not in st.session_state:
    st.session_state.numeric_cols = None

# ====================================================
# OPÃ‡ÃƒO 1 â€“ GERAR HISTOGRAMAS
# ====================================================
if menu == "Gerar Histogramas":

    st.header("ðŸ“ˆ Gerador de Histogramas e RelatÃ³rio AutomÃ¡tico")

    st.subheader("ðŸ“ Dataset Carregado")
    st.write(df.head())

    # Remover colunas sem repetiÃ§Ã£o
    unique_columns = [col for col in df.columns if df[col].nunique() == len(df)]
    df_clean = df.drop(columns=unique_columns, errors="ignore")

    st.subheader("ðŸš® Colunas Removidas (valores totalmente Ãºnicos)")
    st.write(unique_columns if unique_columns else "Nenhuma coluna removida.")

    # Identificar colunas numÃ©ricas
    numeric_cols = df_clean.select_dtypes(include=[np.number]).columns.tolist()

    st.subheader("ðŸ”¢ Colunas NumÃ©ricas Detectadas")
    st.write(numeric_cols)

    # Histogramas
    st.subheader("ðŸ“Š Histogramas")
    for col in numeric_cols:
        st.write(f"### Histograma â€“ {col}")
        fig, ax = plt.subplots(figsize=(7, 4))
        ax.hist(df_clean[col].dropna(), bins=30, color='steelblue', edgecolor='black')
        ax.set_title(f"Histogram of {col}")
        ax.set_xlabel(col)
        ax.set_ylabel("Frequency")
        st.pyplot(fig)

    # Gerar relatÃ³rio
    report = []
    report.append("RELATÃ“RIO DA DISTRIBUIÃ‡ÃƒO DOS DADOS\n")
    report.append("=" * 60 + "\n")

    for col in numeric_cols:
        desc = df_clean[col].describe()
        skew = df_clean[col].skew()
        unique_vals = df_clean[col].nunique()

        text = f"""
Atributo: {col}
-----------------------------------------
MÃ­nimo: {desc['min']}
MÃ¡ximo: {desc['max']}
MÃ©dia: {desc['mean']}
Desvio PadrÃ£o: {desc['std']}
Assimetria (skew): {skew:.4f}
Valores distintos: {unique_vals}

InterpretaÃ§Ã£o:
- {'Assimetria forte â†’ possÃ­vel discretizaÃ§Ã£o necessÃ¡ria.' if abs(skew) > 1 else 'Assimetria moderada ou leve.'}
- {'Poucos valores distintos â†’ Pode ser categÃ³rico (numeric-to-nominal).' if unique_vals <= 10 else 'Atributo contÃ­nuo â†’ Mantido como numÃ©rico.'}
"""
        report.append(text)

    # Colunas que devem virar nominal
    cols_nominal = [col for col in numeric_cols if df_clean[col].nunique() <= 10]
    report.append("\n=== COLUNAS QUE DEVEM VIRAR NOMINAL ===")
    report.append(str(cols_nominal))

    # Mostrar relatÃ³rio
    st.subheader("ðŸ“„ RelatÃ³rio Gerado")
    full_report = "\n".join(report)
    st.text(full_report)

    # Download
    st.download_button(
        label="ðŸ“¥ Baixar RelatÃ³rio TXT",
        data=full_report,
        file_name="relatorio_etapa1.txt",
        mime="text/plain"
    )


# ====================================================
# OPÃ‡ÃƒO 2 â€“ PLACEHOLDER
# ====================================================
elif menu == "ClusterizaÃ§Ã£o (K-Means)":
    st.header("ðŸ¤– ClusterizaÃ§Ã£o com K-Means")

    st.write("### ðŸ” Carregando datasetâ€¦")
    st.write(df.head())

    # ============================================================
    # 2. Identificar atributos numÃ©ricos e transformar cÃ³digos em NOMINAL
    # ============================================================
    st.subheader("ðŸ§© IdentificaÃ§Ã£o de colunas numÃ©ricas e nominais")

    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    st.session_state.numeric_cols = numeric_cols

    cols_nominal = [col for col in numeric_cols if df[col].nunique() <= 10]

    st.write("**Colunas detectadas como NOMINAL:**", cols_nominal)

    df_nominal = df.copy()
    for col in cols_nominal:
        df_nominal[col] = df_nominal[col].astype("category")

    # ============================================================
    # 3. Preparar dados numÃ©ricos para normalizaÃ§Ã£o
    # ============================================================
    st.subheader("âš™ NormalizaÃ§Ã£o MinMax dos atributos contÃ­nuos")

    numeric_continuous = [c for c in numeric_cols if c not in cols_nominal]

    scaler = MinMaxScaler()
    df_scaled = df_nominal.copy()
    df_scaled[numeric_continuous] = scaler.fit_transform(df_nominal[numeric_continuous])

    st.write("**Colunas normalizadas:**", numeric_continuous)

    # ============================================================
    # 4. GrÃ¡fico do ELBOW
    # ============================================================
    st.subheader("ðŸ“‰ MÃ©todo do Cotovelo (Elbow Method)")

    X = df_scaled[numeric_continuous].dropna()

    inertias = []
    K_range = range(2, 16)

    for k in K_range:
        model = KMeans(n_clusters=k, random_state=42)
        model.fit(X)
        inertias.append(model.inertia_)

    fig, ax = plt.subplots(figsize=(8,4))
    ax.plot(K_range, inertias, marker='o')
    ax.set_xlabel("NÃºmero de clusters (k)")
    ax.set_ylabel("InÃ©rcia")
    ax.set_title("MÃ©todo do Cotovelo (Elbow Method)")
    ax.grid()
    st.pyplot(fig)

    st.info("ðŸ“Œ Escolha o valor ideal de K com base no grÃ¡fico acima.")

    # Campo para o usuÃ¡rio definir K
    k_final = st.number_input(
        "Escolha o nÃºmero de clusters (k):",
        min_value=2,
        max_value=15,
        value=12,
        step=1
    )

    # ============================================================
    # 5. Executar K-Means
    # ============================================================
    st.subheader("ðŸš€ Executando K-Means")

    if st.button("Rodar ClusterizaÃ§Ã£o"):
        
        kmeans = KMeans(n_clusters=k_final, random_state=42)
        df_scaled["cluster"] = kmeans.fit_predict(X)

        st.session_state.df_scaled = df_scaled
        st.session_state.numeric_continuous = numeric_continuous
        st.session_state.kmeans_model = kmeans
        st.session_state.X = X
        st.session_state.k_final = k_final
        st.session_state.cols_nominal = cols_nominal

        st.success(f"ClusterizaÃ§Ã£o concluÃ­da com k = {k_final} clusters!")
        st.write(df_scaled.head())

        # ============================================================
        # 6. Gerar ARFF (liac-arff)
        # ============================================================


        arff_data = df_scaled.copy()
        for col in cols_nominal:
            arff_data[col] = arff_data[col].astype(str)

        arff_dict = {
            "relation": "dataset_clusters",
            "attributes": [
                (col, "STRING") if col in cols_nominal else (col, "NUMERIC")
                for col in arff_data.columns
            ],
            "data": arff_data.values.tolist()
        }

        arff_buffer = StringIO()
        arff_dump(arff_dict, arff_buffer)

        # ConteÃºdo do arquivo como string
        arff_file = arff_buffer.getvalue()

        st.download_button(
            "ðŸ“¥ Baixar ARFF Clusterizado",
            arff_file,
            file_name="dataset_clusterizado.arff",
            mime="text/plain"
        )

        # ============================================================
        # 7. Salvar Excel com clusters
        # ============================================================
        df_final_excel = df.copy()
        df_final_excel["cluster"] = df_scaled["cluster"]

        excel_buffer = StringIO()
        df_final_excel.to_csv(excel_buffer, index=False)

        st.download_button(
            "ðŸ“¥ Baixar dataset final com clusters (CSV)",
            excel_buffer.getvalue(),
            file_name="dataset_com_clusters.csv",
            mime="text/csv"
        )

        st.success("Arquivos gerados com sucesso!")

elif menu == "AvaliaÃ§Ã£o dos Clusters":
    st.header("ðŸ“Š AvaliaÃ§Ã£o dos Clusters (K-Means)")

    if st.session_state.df_scaled is None:
        st.error("âš  Execute primeiro a opÃ§Ã£o 2 â€“ ClusterizaÃ§Ã£o (K-Means).")
        st.stop()

    else:
        df_scaled = st.session_state.df_scaled
        numeric_continuous = st.session_state.numeric_continuous
        kmeans = st.session_state.kmeans_model
        X = st.session_state.X
        k_final = st.session_state.k_final
        cols_nominal = st.session_state.cols_nominal

        st.success("Clusters carregados com sucesso! âœ”")

        # ============================================================
        # 1. Preparar dados
        # ============================================================
        X = df_scaled[numeric_continuous].dropna()
        labels = df_scaled["cluster"].values

        st.subheader("ðŸ“ˆ MÃ©tricas de AvaliaÃ§Ã£o")

        # ============================================================
        # 2. MÃ‰TRICAS
        # ============================================================
        sil_score = silhouette_score(X, labels)
        db_score = davies_bouldin_score(X, labels)
        ch_score = calinski_harabasz_score(X, labels)

        st.write(f"**Silhouette Score:** `{sil_score:.4f}`")
        st.write(f"**Davies-Bouldin Index (menor melhor):** `{db_score:.4f}`")
        st.write(f"**Calinski-Harabasz (maior melhor):** `{ch_score:.2f}`")

        # Tamanho dos clusters
        unique, counts = np.unique(labels, return_counts=True)
        cluster_sizes = dict(zip(unique, counts))

        st.write("### ðŸ”¢ Tamanho dos clusters")
        st.write(cluster_sizes)

        # ============================================================
        # 3. CENTROIDES
        # ============================================================
        st.subheader("ðŸ§­ Centroides dos Clusters")
        centroids = pd.DataFrame(kmeans.cluster_centers_, columns=numeric_continuous)
        st.dataframe(centroids.round(4))

        # ============================================================
        # 4. SILHOUETTE PLOT
        # ============================================================
        st.subheader("ðŸ“‰ Silhouette Plot por Cluster")

        sample_silhouette_values = silhouette_samples(X, labels)

        fig, ax = plt.subplots(figsize=(10, 6))
        y_lower = 10

        for i in unique:
            ith = sample_silhouette_values[labels == i]
            ith.sort()

            size_cluster_i = ith.shape[0]
            y_upper = y_lower + size_cluster_i

            ax.fill_betweenx(
                np.arange(y_lower, y_upper),
                0, ith,
                alpha=0.7
            )
            ax.text(-0.05, (y_lower + y_upper) / 2, str(i))
            y_lower = y_upper + 10

        ax.axvline(x=sil_score, color="red", linestyle="--")
        ax.set_title("Silhouette Plot")
        ax.set_xlabel("Coeficiente de Silhouette")
        ax.set_ylabel("Amostras")

        st.pyplot(fig)

        # ============================================================
        # 5. PCA 2D
        # ============================================================
        st.subheader("ðŸ§­ VisualizaÃ§Ã£o PCA 2D dos Clusters")

        pca = PCA(n_components=2)
        pca_result = pca.fit_transform(X)

        df_pca = pd.DataFrame({
            "PC1": pca_result[:, 0],
            "PC2": pca_result[:, 1],
            "cluster": labels
        })

        fig2, ax2 = plt.subplots(figsize=(8, 6))
        sns.scatterplot(
            data=df_pca,
            x="PC1",
            y="PC2",
            hue="cluster",
            palette="tab10",
            ax=ax2
        )
        ax2.set_title("Clusters via PCA 2D")
        st.pyplot(fig2)

        # ============================================================
        # 6. HEATMAP
        # ============================================================
        st.subheader("ðŸ”¥ Heatmap das MÃ©dias por Cluster")

        cluster_means = df_scaled.groupby("cluster")[numeric_continuous].mean()

        fig3, ax3 = plt.subplots(figsize=(12, 6))
        sns.heatmap(cluster_means, annot=True, fmt=".2f", cmap="viridis", ax=ax3)
        ax3.set_title("MÃ©dias dos atributos por cluster")
        st.pyplot(fig3)

elif menu == "Resumo Comparativo":
    st.header("ðŸ“Š Resumo Comparativo Geral")

    if st.session_state.df_scaled is None:
        st.error("âš  Ã‰ necessÃ¡rio executar antes as opÃ§Ãµes 1, 2 e 3!")
        st.stop()

    else:
        df_scaled = st.session_state.df_scaled
        numeric_continuous = st.session_state.numeric_continuous
        kmeans = st.session_state.kmeans_model
        X = st.session_state.X
        k_final = st.session_state.k_final
        cols_nominal = st.session_state.cols_nominal
        
        st.success("Resumo consolidado de todas as etapas.")

        # ---------------------------------------------
        # SEÃ‡ÃƒO 1 â€” RESUMO DA OPÃ‡ÃƒO 1
        # ---------------------------------------------
        st.subheader("ðŸŸ¦ 1. EstatÃ­sticas da AnÃ¡lise ExploratÃ³ria (OpÃ§Ã£o 1)")

        st.write("**NÃºmero de atributos numÃ©ricos:**", len(st.session_state.numeric_cols))
        st.write("**Colunas consideradas NOMINAL (â‰¤ 10 valores Ãºnicos):**")
        st.write(cols_nominal)

        # Assimetria mÃ©dia dos atributos
        skew_values = {col: df[col].skew() for col in st.session_state.numeric_cols}
        mean_skew = np.mean([abs(v) for v in skew_values.values()])

        st.write(f"**Assimetria mÃ©dia dos atributos:** `{mean_skew:.4f}`")


        # ---------------------------------------------
        # SEÃ‡ÃƒO 2 â€” RESUMO DA OPÃ‡ÃƒO 2
        # ---------------------------------------------
        st.subheader("ðŸŸ© 2. Resultados da ClusterizaÃ§Ã£o (OpÃ§Ã£o 2)")

        st.write(f"**NÃºmero de clusters escolhidos (k):** `{k_final}`")

        # Tamanho dos clusters
        unique, counts = np.unique(df_scaled["cluster"].values, return_counts=True)
        cluster_sizes = dict(zip(unique, counts))

        st.write("**Tamanho dos clusters:**")
        st.write(cluster_sizes)

        # NÃºmero de atributos normalizados
        st.write("**Atributos normalizados:**")
        st.write(numeric_continuous)


        # ---------------------------------------------
        # SEÃ‡ÃƒO 3 â€” RESUMO DA AVALIAÃ‡ÃƒO (OpÃ§Ã£o 3)
        # ---------------------------------------------
        st.subheader("ðŸŸ§ 3. AvaliaÃ§Ã£o dos Clusters (OpÃ§Ã£o 3)")

        sil_score = silhouette_score(X, df_scaled["cluster"].values)
        db_score = davies_bouldin_score(X, df_scaled["cluster"].values)
        ch_score = calinski_harabasz_score(X, df_scaled["cluster"].values)

        st.write(f"**Silhouette Score:** `{sil_score:.4f}`")
        st.write(f"**Davies-Bouldin:** `{db_score:.4f}`  (menor melhor)")
        st.write(f"**Calinskiâ€“Harabasz:** `{ch_score:.2f}` (maior melhor)")

        # Melhor e pior cluster (por mÃ©dia de silhouette)
        from sklearn.metrics import silhouette_samples
        sil_samples = silhouette_samples(X, df_scaled["cluster"].values)

        cluster_mean_sil = {
            c: np.mean(sil_samples[df_scaled["cluster"] == c])
            for c in unique
        }

        best_cluster = max(cluster_mean_sil, key=cluster_mean_sil.get)
        worst_cluster = min(cluster_mean_sil, key=cluster_mean_sil.get)

        st.write(f"**Melhor cluster (silhouette mÃ©dio):** `{best_cluster}`")
        st.write(f"**Pior cluster (silhouette mÃ©dio):** `{worst_cluster}`")

        # ---------------------------------------------
        # SEÃ‡ÃƒO 4 â€” VISÃƒO FINAL
        # ---------------------------------------------
        st.subheader("ðŸ ConclusÃ£o Geral")

        st.markdown("""
        ### ðŸ” Insights Gerais:
        - A opÃ§Ã£o 1 confirmou quais atributos sÃ£o realmente relevantes.
        - A opÃ§Ã£o 2 mostrou como os dados se agrupam sob normalizaÃ§Ã£o.
        - A opÃ§Ã£o 3 avaliou matematicamente a qualidade dos clusters.
        - A partir disso, vocÃª pode identificar padrÃµes importantes, clusters dominantes e atributos crÃ­ticos.

        ### ðŸ“¤ ExportaÃ§Ãµes:
        VocÃª pode baixar os arquivos completos gerados na OpÃ§Ã£o 2 (ARFF e Excel).
        """)

elif menu == "Resumo Comparativo e ExportaÃ§Ã£o em PDF":
    st.header("ðŸ“Š Resumo Comparativo Geral + ExportaÃ§Ã£o em PDF")

    if st.session_state.df_scaled is None:
        st.error("âš  Ã‰ necessÃ¡rio executar antes as opÃ§Ãµes 1, 2 e 3!")
        st.stop()
    else:
        df_scaled = st.session_state.df_scaled
        numeric_continuous = st.session_state.numeric_continuous
        kmeans = st.session_state.kmeans_model
        X = st.session_state.X
        k_final = st.session_state.k_final
        cols_nominal = st.session_state.cols_nominal

        st.success("Todas as etapas detectadas. Gerando resumo consolidado.")

        # ===========================
        # 1. Recalcular mÃ©tricas
        # ===========================
        X = df_scaled[numeric_continuous].dropna()
        labels = df_scaled["cluster"].values

        sil_score = silhouette_score(X, labels)
        db_score = davies_bouldin_score(X, labels)
        ch_score = calinski_harabasz_score(X, labels)

        unique, counts = np.unique(labels, return_counts=True)
        cluster_sizes = dict(zip(unique, counts))

        sil_samples = silhouette_samples(X, labels)
        cluster_mean_sil = {c: np.mean(sil_samples[labels == c]) for c in unique}
        best_cluster = max(cluster_mean_sil, key=cluster_mean_sil.get)
        worst_cluster = min(cluster_mean_sil, key=cluster_mean_sil.get)

        # PCA para plot
        pca = PCA(n_components=2)
        pca_result = pca.fit_transform(X)
        df_pca = pd.DataFrame({
            "PC1": pca_result[:, 0],
            "PC2": pca_result[:, 1],
            "cluster": labels
        })

        # ===========================
        # 2. Mostrar resumo na tela
        # ===========================
        st.subheader("ðŸ”¹ MÃ©tricas Gerais")
        st.write(f"**Silhouette Score:** `{sil_score:.4f}`")
        st.write(f"**Davies-Bouldin Index:** `{db_score:.4f}`")
        st.write(f"**Calinski-Harabasz Index:** `{ch_score:.2f}`")
        st.write("**Tamanho dos clusters:**", cluster_sizes)
        st.write(f"**Melhor cluster:** {best_cluster}")
        st.write(f"**Pior cluster:** {worst_cluster}")

        # ===========================
        # 3. Gerar figuras para o PDF
        # ===========================
        import io
        from reportlab.pdfgen import canvas
        from reportlab.lib.pagesizes import A4
        from reportlab.lib.utils import ImageReader

        # --- FIG 1: Silhouette Plot ---
        fig1, ax1 = plt.subplots(figsize=(8, 6))
        y_lower = 10
        for i in unique:
            ith = sil_samples[labels == i]
            ith.sort()
            size_i = ith.shape[0]
            y_upper = y_lower + size_i
            ax1.fill_betweenx(np.arange(y_lower, y_upper), 0, ith, alpha=0.7)
            ax1.text(-0.05, (y_lower + y_upper) / 2, str(i))
            y_lower = y_upper + 10
        ax1.axvline(x=sil_score, color="red", linestyle="--")
        ax1.set_title("Silhouette Plot")
        buf1 = io.BytesIO()
        fig1.savefig(buf1, format="png")
        buf1.seek(0)

        # --- FIG 2: PCA ---
        fig2, ax2 = plt.subplots(figsize=(8, 6))
        sns.scatterplot(data=df_pca, x="PC1", y="PC2", hue="cluster", palette="tab10", ax=ax2)
        ax2.set_title("VisualizaÃ§Ã£o PCA 2D")
        buf2 = io.BytesIO()
        fig2.savefig(buf2, format="png")
        buf2.seek(0)

        # --- FIG 3: Heatmap ---
        cluster_means = df_scaled.groupby("cluster")[numeric_continuous].mean()
        fig3, ax3 = plt.subplots(figsize=(10, 5))
        sns.heatmap(cluster_means, annot=True, fmt=".2f", cmap="viridis", ax=ax3)
        ax3.set_title("Heatmap das MÃ©dias dos Clusters")
        buf3 = io.BytesIO()
        fig3.savefig(buf3, format="png")
        buf3.seek(0)

        # ===========================
        # 4. Criar PDF em memÃ³ria
        # ===========================
        pdf_buffer = io.BytesIO()
        c = canvas.Canvas(pdf_buffer, pagesize=A4)
        width, height = A4
        margin = 40
        y = height - margin

        # TÃTULO
        c.setFont("Helvetica-Bold", 18)
        c.drawString(margin, y, "Resumo Comparativo do Projeto")
        y -= 40

        # TEXTO PRINCIPAL
        c.setFont("Helvetica", 12)
        text = f"""
MÃ©tricas Gerais:
----------------------------
Silhouette Score: {sil_score:.4f}
Davies-Bouldin Index: {db_score:.4f}
Calinski-Harabasz: {ch_score:.2f}

Tamanho dos Clusters: {cluster_sizes}

Melhor cluster (silhouette mÃ©dio): {best_cluster}
Pior cluster (silhouette mÃ©dio): {worst_cluster}
        """
        for line in text.split("\n"):
            c.drawString(margin, y, line)
            y -= 18

        # FunÃ§Ã£o para adicionar imagens no PDF usando ImageReader
        def add_image(buf, y):
            img_height = 250
            img = ImageReader(buf)
            if y < img_height + margin:
                c.showPage()
                y = height - margin - img_height
            c.drawImage(img, margin, y, width=520, height=img_height)
            return y - img_height - 40

        y = add_image(buf1, y)
        y = add_image(buf2, y)
        y = add_image(buf3, y)

        c.save()
        pdf_buffer.seek(0)

        # ===========================
        # 5. BotÃ£o de download PDF
        # ===========================
        st.subheader("ðŸ“¥ Download do PDF Consolidado")
        st.download_button(
            label="ðŸ“„ Baixar RelatÃ³rio PDF",
            data=pdf_buffer,
            file_name="relatorio_comparativo.pdf",
            mime="application/pdf"
        )

        st.success("PDF gerado com sucesso!")
